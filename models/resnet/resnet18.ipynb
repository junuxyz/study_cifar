{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3565c8d",
   "metadata": {},
   "source": [
    "# Vanilla ResNet-18 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66da52",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbd98e",
   "metadata": {},
   "source": [
    "## Define Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3e425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    \"\"\"\n",
    "    A fundamental building block for ResNet Structures, which inclues:\n",
    "    - two convolutional layers each followed by batch normalization and ReLU activation\n",
    "    - a shortcut connection that adds the input to the output, with subsampling if needed\n",
    "    Initial codes are from https://github.com/a-martyn/resnet/blob/master/resnet.py\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, subsample=False):\n",
    "        # s = stride\n",
    "        # z becomes half the size of x when subsample = True\n",
    "        s = 0.5 if subsample else 1.0\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(int(filters*s), filters, kernel_size=3,\n",
    "                               stride=int(1/s), padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2d = nn.Conv2d(filters, filters, kernel_size=3, stride=1,\n",
    "                                padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # shortcut subsample\n",
    "        # this is a mechanism used when the input to the residual block x has different dimensions (either spatial size or number of channels)\n",
    "        # than the output of the convolutional layers z.\n",
    "        # instead of pooling we use stride which makes learned subsampling possible.\n",
    "        self.subsample = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "\n",
    "        # weight initialization based on Kaiming He et al., \"Delving Deep into Rectifiers: \n",
    "        # Surpassing Human-Level Performance on ImageNet Classification\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # calculate variance based on output channels\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def shortcut(self, z, x):\n",
    "        \"\"\"\n",
    "        shortcut connection using identity or subsampling\n",
    "        \"\"\"\n",
    "\n",
    "        # x.shape: (batch_size, C, H, W)\n",
    "        # z.shape: (batch_size, 2 * C, 1/2 * H, 1/2 * W)\n",
    "        # Thus we need to subsample x to match 1/2 * H, 1/2 * W \n",
    "        # and pad channels with zeros to match 2 * C\n",
    "        if x.shape != z.shape:\n",
    "            # reduces the spatial dimensions of x by half using stride 2 pooling\n",
    "            d = self.subsample(x)\n",
    "            # pads the channel dimension with zeros to match z's channels\n",
    "            p = torch.mul(d, 0)\n",
    "            # shape matches: (batch_size, 2 * C, 1/2 * H, 1/2 * W) so we can add\n",
    "            return z + torch.cat((d, p), dim=1)\n",
    "        else:\n",
    "            return z + x\n",
    "        \n",
    "    \n",
    "    def forward(self, x, shortcuts=False):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu1(z)\n",
    "        z = self.conv2d(z)\n",
    "        z = self.bn2(z)\n",
    "\n",
    "        if shortcuts:\n",
    "            z = self.shortcut(z, x)\n",
    "\n",
    "        z = self.relu2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09aa1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A general ResNet model.\n",
    "    Initial codes are from https://github.com/a-martyn/resnet/blob/master/resnet.py\n",
    "    \n",
    "    Args:\n",
    "        n: number of blocks per stack\n",
    "        shortcuts: whether to use shortcut connections\n",
    "\n",
    "    Returns:\n",
    "        output: log-probabilities for each class\n",
    "    \"\"\"\n",
    "    def __init__(self, n, shortcuts=True):\n",
    "        super().__init__()\n",
    "        self.shortcuts = shortcuts\n",
    "\n",
    "        # spatial size is kept the same because of padding=1 and kernel_size=3\n",
    "        # (B, 3, 32, 32) --> (B, 16, 32, 32)\n",
    "        self.convIn = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bnIn = nn.BatchNorm2d(16, track_running_stats=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 16 channels with NO subsampling; repeat n times\n",
    "        # (B, 16, 32, 32) --> (B, 16, 32, 32)\n",
    "        self.stack1 = nn.ModuleList([block(16, subsample=False) for _ in range(n)])\n",
    "        \n",
    "        # double the channels with subsampling\n",
    "        # (B, 16, 32, 32) --> (B, 32, 16, 16)\n",
    "        self.stack2a = block(32, subsample=True)\n",
    "\n",
    "        # 32 channels with NO subsampling(keep the H, W same); repeat n-1 times\n",
    "        # (B, 32, 16, 16) --> (B, 32, 16, 16)\n",
    "        self.stack2b = nn.ModuleList([block(32, subsample=False) for _ in range(n-1)])\n",
    "        \n",
    "        # double the channels with subsampling\n",
    "        # (B, 32, 16, 16) --> (B, 64, 8, 8)\n",
    "        self.stack3a = block(64, subsample=True)\n",
    "        # 64 channels with NO subsampling(keep the H, W same); repeat n-1 times\n",
    "        # (B, 64, 8, 8) --> (B, 64, 8, 8)\n",
    "        self.stack3b = nn.ModuleList([block(64, subsample=False) for _ in range(n-1)])\n",
    "\n",
    "        # global average pooling and output layer\n",
    "        # (B, 64, 8, 8) --> (B, 64, 1, 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # final fully connected layer\n",
    "        self.fcOut = nn.Linear(64, 10, bias=True)\n",
    "        # log-softmax to predict log-probabilities for each class\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.convIn(x)\n",
    "        z = self.bnIn(z)\n",
    "        z = self.relu(z)\n",
    "\n",
    "        for l in self.stack1:\n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "        z = self.stack2a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack2b:\n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "        z = self.stack3a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack3b:\n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "        \n",
    "        z = self.avgpool(z)\n",
    "        # flatten\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.fcOut(z)\n",
    "        return self.softmax(z)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
